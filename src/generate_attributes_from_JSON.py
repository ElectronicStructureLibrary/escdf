import sys
import json
from pprint import pprint
from collections import Counter


# Set up string modifiers:

def def_name(name):
    return name.upper()

def name_string(name):
    return '\"'+name+'\"'

def specs_name(name):
    return name.lower()+'_specs'

def dims_name(name):
    return name.lower()+'_dims'

def attributes_name(name):
    return name.lower() + '_attributes'

def datasets_name(name):
    return name.lower() + '_datasets'

def subgroups_name(name):
    return name.lower() + '_subgroups'

# access routine

def get_attribute(name):
    for a in attributes:
        if a['Name'] == name: 
            return a
    return 0



# set up function to write the ID file

def write_ID_file(x, type):

    if type in x:

        ID_file = open('escdf_'+type.lower()+'_ID.h','w')

        ID_file.write('/***********************************\n')
        ID_file.write(' *       ID   specifications       *\n')
        ID_file.write(' ***********************************\n')
        ID_file.write('\n')
        ID_file.write(' This file is automatically generated. DO NOT EDIT! \n')
        ID_file.write(' In order to update the specifications, edit the file \"attributes_def.json\" \n')
        ID_file.write(' and run \"python generate_attibutes_from_JSON.py\". \n')
        ID_file.write(' */ \n')
        ID_file.write('\n')


        ID_file.write('#ifndef ESCDF_'+type.upper()+'_ID_H\n')
        ID_file.write('#define ESCDF_'+type.upper()+'_ID_H\n\n')

        all = x[type]

        ID_file.write('#include "escdf_common.h"\n\n')

        ID_file.write('typedef enum { \n')
        counter = 0

#        for a in all:
#            ID_file.write('#define ' + def_name(a['Name']) + ' ' + str(counter) + '\n')
#            counter += 1

        for a in all:
            ID_file.write('    '+ def_name(a['Name']) + ', \n')
            counter += 1


        ID_file.write('    '+ 'ESCDF_'+type.upper()+'_UNDEFINED_ID = ESCDF_UNDEFINED_ID' + ' \n')

        ID_file.write('} escdf_'+type.lower().rstrip('s')+'_id_t; \n')

        ID_file.write('\n#endif\n')
        ID_file.close()

# Load input attributes definition file and transfer to dictionary.

definitions_file = open(sys.argv[1],'r')
definitions      = json.load(definitions_file)
definitions_file.close()



# Extract data structures for "Attributes" and "Groups"

print('Attribute file version: ' + definitions['Version'] + '\n')

if 'Attributes' in definitions:
    attributes  =  definitions['Attributes']
else:
    attributes = dict()

if 'Groups'    in definitions:
    groups     =  definitions['Groups']
else:
    groups     = dict()

if 'Datasets' in definitions:
    datasets   = definitions['Datasets']
else:
    datasets   = dict()

if 'SubGroups' in definitions:
    groups    += definitions['SubGroups']
    subgroups  = definitions['SubGroups']
else:
    subgroups  = dict()



print('Found ' + str(len(attributes)) + ' attribute specs definitions. \n')
print('Found ' + str(len(datasets)) + ' dataset specs definitions. \n')
print('Found ' + str(len(groups)) + ' group specs definitions. \n')
print('Found ' + str(len(subgroups)) + ' subgroup specs definitions. \n')

for s in subgroups:
    print(s['Name'])

write_ID_file(definitions,'Attributes')
write_ID_file(definitions,'Datasets')
write_ID_file(definitions,'Groups')

# On the file level, subgroups are treated the same way as groups.
# Hence no extra file is used for subgroup definitions.



# Create header files and write general code lines:

attrib_specs_file = open('escdf_attributes_specs.h','w')

attrib_specs_file.write('/***********************************\n')
attrib_specs_file.write(' *    Attributes specifications    *\n')
attrib_specs_file.write(' ***********************************\n')
attrib_specs_file.write('\n')
attrib_specs_file.write(' This file is automatically generated. DO NOT EDIT! \n')
attrib_specs_file.write(' In order to update the specifications, edit the file \"attributes_def.json\" \n')
attrib_specs_file.write(' and run \"python generate_attibutes_from_JSON.py\". \n')
attrib_specs_file.write(' */ \n')
attrib_specs_file.write('\n')


attrib_specs_file.write('#ifndef ESCDF_ATTRIBUTES_SPECS_H\n')
attrib_specs_file.write('#define ESCDF_ATTRIBUTES_SPECS_H\n\n')
attrib_specs_file.write('#include \"escdf_common.h\" \n')
attrib_specs_file.write('#include \"escdf_attributes.h\" \n')
attrib_specs_file.write('#include \"escdf_attributes_ID.h\" \n\n')


dataset_specs_file = open('escdf_datasets_specs.h','w')

dataset_specs_file.write('/***********************************\n')
dataset_specs_file.write(' *     Datasets specifications     *\n')
dataset_specs_file.write(' ***********************************\n')
dataset_specs_file.write('\n')
dataset_specs_file.write(' This file is automatically generated. DO NOT EDIT! \n')
dataset_specs_file.write(' In order to update the specifications, edit the file \"attributes_def.json\" \n')
dataset_specs_file.write(' and run \"python generate_attibutes_from_JSON.py\". \n')
dataset_specs_file.write(' */ \n')
dataset_specs_file.write('\n')


dataset_specs_file.write('#ifndef ESCDF_DATASETS_SPECS_H\n')
dataset_specs_file.write('#define ESCDF_DATASETS_SPECS_H\n\n')
dataset_specs_file.write('#include \"escdf_common.h\" \n')
dataset_specs_file.write('#include \"escdf_datasets.h\" \n')
dataset_specs_file.write('#include \"escdf_datasets_ID.h\" \n')
dataset_specs_file.write('#include \"escdf_attributes_specs.h\" \n\n')

group_specs_file = open('escdf_groups_specs.h','w')

group_specs_file.write('/***********************************\n')
group_specs_file.write(' *       Group specifications      *\n')
group_specs_file.write(' ***********************************\n')
group_specs_file.write('\n')
group_specs_file.write(' This file is automatically generated. DO NOT EDIT! \n')
group_specs_file.write(' In order to update the specifications, edit the file \"attributes_def.json\" \n')
group_specs_file.write(' and run \"python generate_attibutes_from_JSON.py\". \n')
group_specs_file.write(' */ \n')
group_specs_file.write('\n')


group_specs_file.write('#ifndef ESCDF_GROUPS_SPECS_H\n')
group_specs_file.write('#define ESCDF_GROUPS_SPECS_H\n\n')
group_specs_file.write('#include \"escdf_group.h\" \n')
group_specs_file.write('#include \"escdf_groups_ID.h\" \n')
group_specs_file.write('#include \"escdf_error.h\" \n')
group_specs_file.write('#include \"escdf_attributes_specs.h\" \n')
group_specs_file.write('#include \"escdf_datasets_specs.h\" \n\n')


# Initialise some data structures
# ===============================


# Lists of all found symbols
#
#   use that to check whether an attribute, dataset or subgroup, assigned to a group, does actually exist.

attribute_list = []       
dataset_list   = []
subgroup_list  = []


# Count how often a given attribute is used
#
#   use that counter to check whether an attribute is not assigne to any group

use_counter = Counter()   


# Create attribute_specs definitions 

for a in attributes:

    attribute_name = a['Name']

    ID_name = def_name(attribute_name)

    attribute_list.append(attribute_name)
    use_counter[attribute_name] = 0

    if 'String_length' in a:
        stringlength = a['String_length']
    else:
        stringlength = 0

    if a['Dimensions'] == 0:
        dims_pointer = 'NULL'
    else:
        dims_names = ''
        for p in a['Dims_definitions']:
            dims_names += '\n    &'+specs_name(p) + ','
    
        dims_names = dims_names.rstrip(',')
        attrib_specs_file.write('const escdf_attribute_specs_t *' + dims_name(attribute_name) 
                                + '[] = { ' + dims_names + ' \n};\n\n')
        dims_pointer = dims_name(attribute_name)

    attrib_specs_file.write('const escdf_attribute_specs_t '+specs_name(attribute_name) + ' = \n')
    attrib_specs_file.write('    { '+ ID_name + ', ' + name_string( attribute_name )+ ', ' + a['Data_type'] 
                            + ', ' +str(stringlength) + ', ' 
                            + str(a['Dimensions']) +', ' + dims_pointer + ' }; \n\n')
   

# Create dataset specs definitions:

for d in datasets:

    dataset_name = d['Name']

    print('Processing: ' + dataset_name+' \n')

    ID_name = def_name(dataset_name)

    dataset_list.append(dataset_name)
    use_counter[dataset_name] = 0

    if 'String_length' in d:
        stringlength = d['String_length']
    else:
        stringlength = 0



    if d['Dimensions'] == 0:
        dims_pointer = 'NULL'
    else:
        dims_names = ''
        for p in d['Dims_definitions']:
            dims_names += '\n    &' + specs_name(p) + ','
            aa = get_attribute(p)
            num_dims = aa['Dimensions']
            if num_dims > 0:
                print(p + ': ' + str(num_dims) + '\n')
                compact = 'true, '
            else:
                compact = 'false, '
    
        dims_names = dims_names.rstrip(',')
        dataset_specs_file.write('const escdf_attribute_specs_t *' + dims_name(dataset_name) + '[] = { ' + dims_names + ' \n};\n\n')
        dims_pointer = dims_name(dataset_name)
        if 'Disordered_Allowed' in d:
            if d['Disordered_Allowed']=='Yes': 
                disordered = 'true, '
            else:   
                disordered = 'false, '
        else:
            disordered = 'false, '

    dataset_specs_file.write('const escdf_dataset_specs_t '+specs_name(dataset_name) + ' = \n')
    dataset_specs_file.write('    { '+ ID_name + ', ' + name_string( dataset_name )+ ', ' + d['Data_type'] + ', ' +str(stringlength) + ', ' 
                            + str(d['Dimensions']) +', '+ disordered + compact + dims_pointer + ' }; \n\n')


# Create group specs definitions:

for s in subgroups:

    subgroup_list.append(s['Name'])
    group_specs_file.write('const escdf_group_specs_t '+specs_name(s['Name']) +';\n')

group_specs_file.write('\n\n')

for g in groups:

    ID_name = def_name(g['Name'])

    attrib_list = ''
    datas_list = ''
    subs_list = ''

    g['Num_Attrib'] = 0
    g['Num_Datasets'] = 0
    g['Num_SubGroups'] = 0

    if 'Attributes' in g:
    
        for a in g['Attributes']:
            if a in attribute_list:
                attrib_list += '\n    &'+ specs_name(a) + ','
                g['Num_Attrib'] += 1
                use_counter[a] += 1
            else:
                print ('WARNING: attribute '+ a + ' not found!')

        if g['Num_Attrib'] > 0:
            group_specs_file.write('const escdf_attribute_specs_t *'+attributes_name(g['Name'])+'[] = { ')
            group_specs_file.write(attrib_list.rstrip(',') + '\n')
            group_specs_file.write('};\n\n')

    if 'Datasets' in g:

        for d in g['Datasets']:
            if d in dataset_list:
                datas_list += '\n    &'+ specs_name(d) + ','
                g['Num_Datasets'] += 1
                use_counter[d] += 1
            else:
                print ('WARNING: dataset '+ d + ' not found!')
        if g['Num_Datasets'] > 0:
            group_specs_file.write('const escdf_dataset_specs_t *'+datasets_name(g['Name'])+'[] = { ')
            group_specs_file.write(datas_list.rstrip(',') + '\n')
            group_specs_file.write('};\n\n')

    if 'SubGroups' in g:

        for s in g['SubGroups']:
            if s in subgroup_list:
                subs_list += '\n   &'+ specs_name(s) + ','
                g['Num_SubGroups'] += 1
                use_counter[s] += 1
                print('Adding subgroup '+s+' to group '+g['Name'])
            else:
                print ( 'WARNING: subgroup '+ s +' not found!')

        if g['Num_SubGroups'] > 0:
            group_specs_file.write('const escdf_group_specs_t *'+subgroups_name(g['Name'])+'[] = { ')
            group_specs_file.write(subs_list.rstrip(',') + '\n')
            group_specs_file.write('};\n\n')

for g in groups:

    if g['Num_Attrib'] == 0: 
        attrib_name = 'NULL'
    else:   
        attrib_name = attributes_name(g['Name'])

    if g['Num_Datasets'] == 0: 
        datas_name = 'NULL'
    else:   
        datas_name = datasets_name(g['Name'])

    if g['Num_SubGroups'] == 0:
        subs_name = 'NULL'
    else:
        subs_name = subgroups_name(g['Name'])
        
        
    group_specs_file.write('const escdf_group_specs_t '+specs_name(g['Name']) +' = {\n    ')
    group_specs_file.write(   def_name(g['Name']) + ', ' + name_string(g['Name'])  + ', ' 
                            + str(g['Num_Attrib']) + ', '
                            + attrib_name + ', ' 
                            + str(g['Num_Datasets']) + ', ' 
                            + datas_name + ', '
                            + str(g['Num_SubGroups']) + ', '
                            + subs_name + '\n' )

    group_specs_file.write('};\n \n')
    

# print some information and warnings:

print('')

for a in attribute_list:
    if a not in use_counter.elements():
        print('WARNING: ' + a + ' is not referenced in any group!')

print('')
        
for a in list(use_counter):
    if use_counter[a] > 1:
        print('INFO: ' + a + ' used ' + str(use_counter[a]) + ' times.')


# Create function to register groups

group_specs_file.write('escdf_errno_t escdf_register_all_group_specs() { \n\n')
group_specs_file.write('    escdf_errno_t error = ESCDF_SUCCESS; \n')

for g in groups:
#    if g['Num_Attrib'] + g['Num_Datasets'] + g['Num_SubGroups']>0:
    group_specs_file.write('    FULFILL_OR_RETURN(escdf_group_specs_register(&'+specs_name(g['Name'])+') == ESCDF_SUCCESS, ESCDF_ERROR); \n')

group_specs_file.write('    return ESCDF_SUCCESS;\n}; \n')



attrib_specs_file.write("\n#endif \n")
attrib_specs_file.close()

dataset_specs_file.write("\n#endif \n")
dataset_specs_file.close()

group_specs_file.write("\n#endif \n")
group_specs_file.close()

print('\n')
print(attrib_specs_file.name + ' written.')
print(group_specs_file.name  + ' written.')
print(dataset_specs_file.name  + ' written.')
print('\n')

